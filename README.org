* yamlett - Yet Another Machine Learning Experiment Tracking Tool
:PROPERTIES:
:header-args:jupyter-python: :session yamlett :results value raw :async yes
:END:

=yamlett= provides you with a simple but flexible way to organize and track your
ML experiments.
** MongoDB PoC
#+begin_src jupyter-python
import pymongo
m = pymongo.MongoClient()
#+end_src

#+RESULTS:

#+begin_src jupyter-python
m.list_database_names()
#+end_src

#+RESULTS:
| admin | config | local | turf | yamlett |

#+begin_src jupyter-python
from uuid import uuid4
run_id = uuid4().hex
run_id
#+end_src

#+RESULTS:
: f0380d099f4242f68b59de84cfc0ec7d

#+begin_src jupyter-python
r = m.yamlett.runs.update_one({"_id": run_id}, {"$set": {"la": 1}})
r
#+end_src

#+RESULTS:
: <pymongo.results.UpdateResult at 0x7f9b6aa70870>

#+begin_src jupyter-python
r.modified_count
#+end_src

#+RESULTS:
: 0

#+begin_src jupyter-python
m.yamlett.runs.insert_one({"_id": run_id})
#+end_src

#+RESULTS:
: <pymongo.results.InsertOneResult at 0x7fe474f9cd70>

#+begin_src jupyter-python
# log("f1_score", 0.97)
m.yamlett.runs.update_one({"_id": run_id}, {"$set":  {"f1_score": 0.97}})
#+end_src

#+RESULTS:
: <pymongo.results.UpdateResult at 0x7fe47479f6e0>

#+begin_src jupyter-python
# log("metrics", {"f1_score": 0.95, "precision_score": .94})
m.yamlett.runs.update_one({"_id": run_id}, {"$set":  {"metrics": {"f1_score": 0.95, "precision_score": 0.94}}})
#+end_src

#+RESULTS:
: <pymongo.results.UpdateResult at 0x7fe474f9c820>

#+begin_src jupyter-python
# log("metrics.f1_score", 0.98)
m.yamlett.runs.update_one({"_id": run_id}, {"$set": {"metrics.f1_score": 0.98}})
#+end_src

#+RESULTS:
: <pymongo.results.UpdateResult at 0x7fe475bf8a00>

#+begin_src jupyter-python
config = dict(
    dataset=dict(
        name="breast_cancer",
        version="1.0",
    ),
    model=dict(
        kind="logistic regression",
        parameters=dict(
            regularization=0.01,
            fit_intercept=False
        )
    )
)

# log("config", config)
m.yamlett.runs.update_one({"_id": run_id}, {"$set": {"config": config}})
#+end_src

#+RESULTS:
: <pymongo.results.UpdateResult at 0x7fe47478a3c0>

#+begin_src jupyter-python
m.close()
#+end_src

** API UI
#+begin_src jupyter-python :eval no
from yamlett import experiment

with experiment() as E:
    dataset = "breast_cancer"
    s3_folder = "s3://virgile/breast_cancer"
    X = pd.read_parquet(f"{s3_folder}/features.parquet")
    y = pd.read_parquet(f"{s3_folder}/labels.parquet")
    
    E.record("dataset", {
        "name": dataset,
        "path": s3_folder,
        "n_observations": X.shape[0],
        "n_features": X.shape[1],
        "class_distribution": y.value_counts().to_dict()
    })
#+end_src


** Example
#+begin_src jupyter-python
%load_ext autoreload
%autoreload 2
#+end_src

#+RESULTS:

#+begin_src jupyter-python :results raw output
from yamlett.tracking import Run
import numpy as np
from sklearn.datasets import load_boston
from sklearn.model_selection import GridSearchCV, RepeatedKFold
from sklearn.linear_model import LinearRegression, Ridge

X, y = load_boston(return_X_y=True)
param_grid = {
    "fit_intercept": [True, False],
    "normalize": [True, False],
    "alpha": np.linspace(0, 1, 5),
}
grid_search = GridSearchCV(
    estimator=Ridge(),
    param_grid=param_grid,
    cv=RepeatedKFold(random_state=0),
    scoring="neg_mean_squared_error",
    refit=True,
    n_jobs=4,
)

model = grid_search.fit(X, y)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
with Run(port=27018) as r:
    config = dict(
        dataset=dict(
            name="boston",
            path="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html#sklearn.datasets.load_boston",
        ),
        model=dict(
            type=model.best_estimator_.__class__.__name__,
            parameters=model.best_estimator_.get_params(),
        ),
    )
    r.store("config", config)
    metrics = [
        {
            "name": "mse",
            "mean": model.cv_results_["mean_test_score"].mean(),
            "stddev": model.cv_results_["mean_test_score"].std(),
        },
        {"name": "accuracy", "mean": np.random.rand(), "stddev": np.random.rand() / 20},
        {"name": "f1_score", "mean": np.random.rand(), "stddev": np.random.rand() / 20},
    ]
    r.store("metrics", metrics)
    # r.store("best_model", model.best_estimator_, pickle=True)

print(r.id)
#+end_src

#+RESULTS:
: b53988648ba249bdb113ea177d9304ad
* Local Variables
# Local Variables:
# eval: (add-hook 'after-save-hook (lambda ()(org-babel-tangle)) nil t)
# End:

